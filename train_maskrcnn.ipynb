{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "tensor2pil = ToPILImage()\n",
    "from load_data import Data\n",
    "from dataset import FrameDataset\n",
    "from transformation import FrameTransform\n",
    "from visualize import visualize_video\n",
    "sys.path.append('mask-rcnn')\n",
    "from maskrcnn import MaskRCNN\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "data = Data(data_path)\n",
    "random_state = np.random.RandomState(seed=1)\n",
    "# reduce data size for test purposes\n",
    "#data, _ = data.train_test_split(test_size=0.90)\n",
    "train_data, valid_data = data.train_test_split()\n",
    "print('full data', len(data))\n",
    "print('train data', len(train_data))\n",
    "print('valid data', len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 4\n",
    "GPU_NUM = 0\n",
    "TRAIN_RPN_ONLY = False\n",
    "MODEL_SAVE_PATH = './model'\n",
    "max_object_count = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = FrameTransform(size=(400, 512))\n",
    "train_dataset = FrameDataset(train_data, transform=transform.transform, max_object_count=max_object_count)\n",
    "val_dataset = FrameDataset(valid_data, transform=transform.transform, max_object_count=max_object_count)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.visualize import draw_boxes, display_instances\n",
    "\n",
    "check_count = 0\n",
    "for sample in train_dataloader:\n",
    "    check_count += 1\n",
    "    if check_count < 20:\n",
    "        continue\n",
    "    if check_count > 23:\n",
    "        break\n",
    "    print(sample['bboxes'].type())\n",
    "    for i in range(train_dataloader.batch_size):\n",
    "        image = tensor2pil(sample['image'][i])\n",
    "        gt_mask = sample['mask'].squeeze(2)\n",
    "        draw_boxes(np.array(image), refined_boxes=sample['bboxes'][i].numpy(), masks=gt_mask[i].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# define train, val, test function\n",
    "#==================================\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "import time\n",
    "\n",
    "def train_epoch(model, optimizer, epoch, loader):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for sample in tqdm_notebook(loader):\n",
    "        image = sample['image'].cuda()\n",
    "        gt_cls = sample['classes'].cuda()\n",
    "        gt_bbox = sample['bboxes'].cuda()\n",
    "        gt_mask = sample['mask'].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        result, loss = model(image, gt_cls, gt_bbox, gt_mask)\n",
    "        train_loss += loss.data\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "    output_str = \"Train epoch: {} \\t Train loss: {} \\t Time elapse: {}s\".format(\n",
    "        epoch, round(train_loss[0].item() / len(loader), 4), int(time.time() - start_time))\n",
    "    print(output_str)\n",
    "    \n",
    "def val_epoch(model, epoch, loader):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    val_loss = 0\n",
    "    \n",
    "    for sample in tqdm_notebook(loader):\n",
    "        image = sample['image'].cuda()\n",
    "        gt_cls = sample['classes'].cuda()\n",
    "        gt_bbox = sample['bboxes'].cuda()\n",
    "        gt_mask = sample['mask'].cuda()\n",
    "    \n",
    "        result, loss = model(image, gt_cls, gt_bbox, gt_mask)\n",
    "        sample = transform.reverse_transform(sample)\n",
    "        \n",
    "        assert BATCH_SIZE == 1\n",
    "        results.extend(result)\n",
    "        val_loss += loss.data\n",
    "        \n",
    "    output_str = \"Val loss: {}\".format(round(val_loss[0].item() / len(loader), 4))\n",
    "    print(output_str)\n",
    "\n",
    "def train(model, optimizer, epochs):\n",
    "    for epoch in range(1, epochs + 1): \n",
    "        train_epoch(model, optimizer, epoch, train_dataloader)\n",
    "        val_epoch(model, epoch, val_dataloader)\n",
    "        model_path = os.path.join(MODEL_SAVE_PATH, \"./maskrcnn_%d.state\" % epoch)\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# training\n",
    "#==========\n",
    "\n",
    "\n",
    "with torch.cuda.device(GPU_NUM):\n",
    "    model = MaskRCNN(num_classes=data.num_classes, pretrained=\"imagenet\").cuda()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                 lr=0.0001, weight_decay=0.0001)\n",
    "    train(model, optimizer, 10, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "model_path = os.path.join(MODEL_SAVE_PATH, \"./maskrcnn_%d.state\" % epoch)\n",
    "with torch.cuda.device(GPU_NUM):\n",
    "    model = MaskRCNN(num_classes=data.num_classes, pretrained=\"imagenet\").cuda()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=lambda storage, loc: storage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_epoch(model, 1, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.visualize import draw_boxes, display_instances\n",
    "results = []\n",
    "counter = 0\n",
    "for sample in tqdm_notebook(val_dataloader):\n",
    "    counter += 1\n",
    "    if counter < 37:\n",
    "        continue\n",
    "    image = sample['image'].cuda()\n",
    "    gt_cls = sample['classes'].cuda()\n",
    "    gt_bbox = sample['bboxes'].cuda()\n",
    "    gt_mask = sample['mask'].cuda()\n",
    "\n",
    "    result, loss = model(image, gt_cls, gt_bbox, gt_mask)\n",
    "    bbox_pred = []\n",
    "    masks_pred = []\n",
    "    classes = []\n",
    "    print(result[0])\n",
    "\n",
    "    assert BATCH_SIZE == 1\n",
    "    for obj in result[0]:\n",
    "        #img_ids.append(image_id[0])\n",
    "        #shapes.append((height, width))\n",
    "        #props.append(obj['proposal'].numpy())\n",
    "        if not TRAIN_RPN_ONLY:\n",
    "            masks_pred.append(obj['mask_pred'].numpy())\n",
    "            bbox_pred.append(obj['bbox_pred'].numpy())\n",
    "            classes.append(obj['cls_pred'])\n",
    "    results.extend(result)\n",
    "    image = tensor2pil(sample['image'][0])\n",
    "    gt_mask = sample['mask'].squeeze(2)\n",
    "    draw_boxes(np.array(image), refined_boxes=sample['bboxes'][0].numpy(), masks=gt_mask[0].numpy())\n",
    "    masks_pred = np.array(masks_pred)\n",
    "    draw_boxes(np.array(image), refined_boxes=bbox_pred, masks=masks_pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
